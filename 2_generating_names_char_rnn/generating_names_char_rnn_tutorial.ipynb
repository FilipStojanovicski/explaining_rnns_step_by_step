{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a94b539",
   "metadata": {},
   "source": [
    "# Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca6915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "lang_names = {}\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "for filename in findFiles('../data/names/*.txt'):\n",
    "    lang = os.path.splitext(os.path.basename(filename))[0]\n",
    "    names = readLines(filename)\n",
    "    lang_names[lang] = names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f4466",
   "metadata": {},
   "source": [
    "# Encode data into numerical tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f731c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = dict(enumerate(list(all_letters) + [\"<EOS>\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4161ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {j:i for i,j in idx2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9debff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(idx2char.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84af4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = list(lang_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687b7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2lang = dict(enumerate(langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a91054",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang2idx = {j:i for i,j in idx2lang.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c81de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_langs = len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c577a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langToTensor(lang):\n",
    "    tensor = torch.zeros(n_langs)\n",
    "    tensor[lang2idx[lang]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd8c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameToTensor(name):\n",
    "    tensor = torch.zeros(len(name), n_vocab)\n",
    "\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i][char2idx[char]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0bdede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameToTarget(name):\n",
    "    name = list(name) + [\"<EOS>\"]\n",
    "    tensor = [char2idx[i] for i in name]\n",
    "    tensor = tensor[1:]\n",
    "    tensor = torch.tensor(tensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b6ee4",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f3379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size + n_langs, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size + n_langs, output_size)\n",
    "        self.o2o = nn.Linear(output_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 0)\n",
    "    \n",
    "    def forward(self, input, hidden, lang):\n",
    "        combined = torch.cat([input, hidden, lang])\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        combined_output = torch.cat([hidden, output])\n",
    "        output = self.o2o(combined_output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd21e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = list(lang_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99187648",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_langs = len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de978ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "165d1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size = n_vocab, hidden_size = n_hidden, output_size = n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd265a7b",
   "metadata": {},
   "source": [
    "# Pass an example through our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ee9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Smith\"\n",
    "name_tensor = nameToTensor(name)\n",
    "lang = \"English\"\n",
    "lang_tensor = langToTensor(lang)\n",
    "target = nameToTarget(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192c440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = rnn.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f5a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = rnn(name_tensor[0], hidden, lang_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872fc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = rnn(name_tensor[1], hidden, lang_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52209183",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cfebed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0576, -4.1108, -4.1347, -4.0549, -4.0846, -4.0762, -4.1781, -3.9412,\n",
       "        -3.9231, -4.1609, -4.0049, -4.0174, -3.9572, -3.9181, -4.0378, -4.1057,\n",
       "        -4.0539, -4.0511, -4.0650, -4.0987, -4.1339, -4.2165, -4.0419, -4.1481,\n",
       "        -4.0834, -4.0556, -4.1387, -4.1370, -3.9936, -4.0773, -4.0216, -3.9261,\n",
       "        -3.9859, -4.0089, -4.1286, -4.1321, -3.9802, -4.0828, -4.1310, -4.1619,\n",
       "        -4.1531, -4.1782, -3.9518, -4.0287, -4.1153, -4.1192, -4.0752, -4.1033,\n",
       "        -4.1271, -4.1491, -4.1394, -3.9787, -3.9808, -3.9511, -4.0771, -3.9696,\n",
       "        -3.9472, -4.0104], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77bb5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(output, target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ba28c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9231, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892a2a4",
   "metadata": {},
   "source": [
    "# Train our NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7df9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomExample():\n",
    "    lang = random.sample(langs, 1)[0]\n",
    "    name = random.sample(lang_names[lang], 1)[0]\n",
    "    return lang, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc775b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  1000\n",
      "Average loss:  2.943\n",
      "Iterations:  2000\n",
      "Average loss:  2.634\n",
      "Iterations:  3000\n",
      "Average loss:  2.4685\n",
      "Iterations:  4000\n",
      "Average loss:  2.4303\n",
      "Iterations:  5000\n",
      "Average loss:  2.3475\n",
      "Iterations:  6000\n",
      "Average loss:  2.2893\n",
      "Iterations:  7000\n",
      "Average loss:  2.3009\n",
      "Iterations:  8000\n",
      "Average loss:  2.2223\n",
      "Iterations:  9000\n",
      "Average loss:  2.241\n",
      "Iterations:  10000\n",
      "Average loss:  2.2154\n",
      "Iterations:  11000\n",
      "Average loss:  2.2233\n",
      "Iterations:  12000\n",
      "Average loss:  2.2099\n",
      "Iterations:  13000\n",
      "Average loss:  2.1868\n",
      "Iterations:  14000\n",
      "Average loss:  2.161\n",
      "Iterations:  15000\n",
      "Average loss:  2.1644\n",
      "Iterations:  16000\n",
      "Average loss:  2.1616\n",
      "Iterations:  17000\n",
      "Average loss:  2.1536\n",
      "Iterations:  18000\n",
      "Average loss:  2.1447\n",
      "Iterations:  19000\n",
      "Average loss:  2.1448\n",
      "Iterations:  20000\n",
      "Average loss:  2.1277\n",
      "Iterations:  21000\n",
      "Average loss:  2.1217\n",
      "Iterations:  22000\n",
      "Average loss:  2.0897\n",
      "Iterations:  23000\n",
      "Average loss:  2.1298\n",
      "Iterations:  24000\n",
      "Average loss:  2.1147\n",
      "Iterations:  25000\n",
      "Average loss:  2.0898\n",
      "Iterations:  26000\n",
      "Average loss:  2.0935\n",
      "Iterations:  27000\n",
      "Average loss:  2.0782\n",
      "Iterations:  28000\n",
      "Average loss:  2.1042\n",
      "Iterations:  29000\n",
      "Average loss:  2.0747\n",
      "Iterations:  30000\n",
      "Average loss:  2.0846\n",
      "Iterations:  31000\n",
      "Average loss:  2.0877\n",
      "Iterations:  32000\n",
      "Average loss:  2.0731\n",
      "Iterations:  33000\n",
      "Average loss:  2.0554\n",
      "Iterations:  34000\n",
      "Average loss:  2.0799\n",
      "Iterations:  35000\n",
      "Average loss:  2.0579\n",
      "Iterations:  36000\n",
      "Average loss:  2.0787\n",
      "Iterations:  37000\n",
      "Average loss:  2.078\n",
      "Iterations:  38000\n",
      "Average loss:  2.0776\n",
      "Iterations:  39000\n",
      "Average loss:  2.0687\n",
      "Iterations:  40000\n",
      "Average loss:  2.0521\n",
      "Iterations:  41000\n",
      "Average loss:  2.0406\n",
      "Iterations:  42000\n",
      "Average loss:  2.0393\n",
      "Iterations:  43000\n",
      "Average loss:  2.0638\n",
      "Iterations:  44000\n",
      "Average loss:  2.0619\n",
      "Iterations:  45000\n",
      "Average loss:  2.0692\n",
      "Iterations:  46000\n",
      "Average loss:  2.0206\n",
      "Iterations:  47000\n",
      "Average loss:  2.0305\n",
      "Iterations:  48000\n",
      "Average loss:  2.0487\n",
      "Iterations:  49000\n",
      "Average loss:  2.0419\n",
      "Iterations:  50000\n",
      "Average loss:  2.0539\n",
      "Iterations:  51000\n",
      "Average loss:  2.0424\n",
      "Iterations:  52000\n",
      "Average loss:  2.0171\n",
      "Iterations:  53000\n",
      "Average loss:  2.052\n",
      "Iterations:  54000\n",
      "Average loss:  2.0425\n",
      "Iterations:  55000\n",
      "Average loss:  2.0558\n",
      "Iterations:  56000\n",
      "Average loss:  2.0134\n",
      "Iterations:  57000\n",
      "Average loss:  2.0195\n",
      "Iterations:  58000\n",
      "Average loss:  2.0441\n",
      "Iterations:  59000\n",
      "Average loss:  2.0153\n",
      "Iterations:  60000\n",
      "Average loss:  2.0418\n",
      "Iterations:  61000\n",
      "Average loss:  2.0626\n",
      "Iterations:  62000\n",
      "Average loss:  2.0459\n",
      "Iterations:  63000\n",
      "Average loss:  2.0097\n",
      "Iterations:  64000\n",
      "Average loss:  2.0331\n",
      "Iterations:  65000\n",
      "Average loss:  2.032\n",
      "Iterations:  66000\n",
      "Average loss:  2.0365\n",
      "Iterations:  67000\n",
      "Average loss:  1.9975\n",
      "Iterations:  68000\n",
      "Average loss:  2.0261\n",
      "Iterations:  69000\n",
      "Average loss:  2.054\n",
      "Iterations:  70000\n",
      "Average loss:  2.0229\n",
      "Iterations:  71000\n",
      "Average loss:  2.0113\n",
      "Iterations:  72000\n",
      "Average loss:  1.9846\n",
      "Iterations:  73000\n",
      "Average loss:  1.9996\n",
      "Iterations:  74000\n",
      "Average loss:  2.0377\n",
      "Iterations:  75000\n",
      "Average loss:  2.0307\n",
      "Iterations:  76000\n",
      "Average loss:  1.9999\n",
      "Iterations:  77000\n",
      "Average loss:  2.0494\n",
      "Iterations:  78000\n",
      "Average loss:  2.0074\n",
      "Iterations:  79000\n",
      "Average loss:  2.0615\n",
      "Iterations:  80000\n",
      "Average loss:  2.0371\n",
      "Iterations:  81000\n",
      "Average loss:  2.0283\n",
      "Iterations:  82000\n",
      "Average loss:  2.0398\n",
      "Iterations:  83000\n",
      "Average loss:  2.0215\n",
      "Iterations:  84000\n",
      "Average loss:  2.0208\n",
      "Iterations:  85000\n",
      "Average loss:  2.024\n",
      "Iterations:  86000\n",
      "Average loss:  1.9888\n",
      "Iterations:  87000\n",
      "Average loss:  2.0234\n",
      "Iterations:  88000\n",
      "Average loss:  2.0148\n"
     ]
    }
   ],
   "source": [
    "n_iters = 100000\n",
    "learning_rate = 0.005\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "avg_loss = 0\n",
    "n_checkpoint = 1000\n",
    "for i in range(1, n_iters + 1):\n",
    "    \n",
    "    # Initialize hidden state\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    lang, name = randomExample()\n",
    "    \n",
    "    input = nameToTensor(name)\n",
    "    lang_tensor = langToTensor(lang)\n",
    "    target = nameToTarget(name)\n",
    "    \n",
    "    loss = torch.Tensor([0])\n",
    "    for j in range(input.size()[0]):\n",
    "        output, hidden = rnn(input[j], hidden, lang_tensor)\n",
    "        l = criterion(output, target[j])\n",
    "        loss += l\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    loss /= input.size()[0]\n",
    "    \n",
    "    avg_loss += loss\n",
    "        \n",
    "    if i % n_checkpoint == 0:\n",
    "        avg_loss /= n_checkpoint\n",
    "        print(\"Iterations: \", i)\n",
    "        print(\"Average loss: \", round(avg_loss.item(), 4))\n",
    "        \n",
    "        all_losses.append((i, round(avg_loss.item(), 4)))\n",
    "        \n",
    "        avg_loss = 0\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha = -learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d92fec",
   "metadata": {},
   "source": [
    "# Plot the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede820c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot([x[0] for x in all_losses], [x[1] for x in all_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ab72f",
   "metadata": {},
   "source": [
    "# Evaluating on some inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db684db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(starting_letters, lang):\n",
    "    predicted_name = starting_letters\n",
    "\n",
    "    hidden = rnn.initHidden()\n",
    "    lang_tensor = langToTensor(lang)\n",
    "    for i in range(len(starting_letters)):\n",
    "        input = nameToTensor(starting_letters[i])[0]\n",
    "        output, hidden = rnn(input, hidden, lang_tensor)\n",
    "\n",
    "    val, idx = output.topk(3, 0, True)\n",
    "    next_letter = idx2char[idx[0].item()]\n",
    "    \n",
    "    if next_letter == \"<EOS>\":\n",
    "        return predicted_name\n",
    "            \n",
    "    predicted_name += next_letter\n",
    "    input = nameToTensor(next_letter)[0]\n",
    "\n",
    "    max_length = 20\n",
    "    for i in range(len(starting_letters), max_length):\n",
    "        output, hidden = rnn(input, hidden, lang_tensor)\n",
    "\n",
    "        val, idx = output.topk(3, 0, True)\n",
    "        next_letter = idx2char[idx[0].item()]\n",
    "\n",
    "        if next_letter == \"<EOS>\":\n",
    "            break\n",
    "        else:\n",
    "            predicted_name += next_letter\n",
    "            input = nameToTensor(next_letter)[0]\n",
    "    return predicted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174934f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = \"Filip\"\n",
    "print(\"Starting Letters: \", letters)\n",
    "for lang in langs:\n",
    "    print(\"Language: \", lang)\n",
    "    predicted_name = predict(starting_letters = letters, lang = lang)\n",
    "    print(\"Predicted Name: \", predicted_name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e489c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_from_scratch-kernel",
   "language": "python",
   "name": "nlp_from_scratch-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
